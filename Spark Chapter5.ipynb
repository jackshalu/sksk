{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession sample\n",
    "from pyspark import SparkContext,SparkConf\n",
    "from pyspark.sql import Row\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession.builder.appName(\"StackOverFlowSurvey\").getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns,Rows and collect row objects\n",
    "#Dataframes are untyped APIs (runtime) and Datasets  are strongly typed API (compile time)\n",
    "\n",
    "df = spark.range(100).toDF(\"num\")\n",
    "df10 = df.select(df[\"num\"] + 10)\n",
    "df.show()\n",
    "df10.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read a Dataframe from datasource\n",
    "\n",
    "#dfjson = spark.read.format(\"json\").load(\"file:///Users/jackshalu/Documents/Spark-The-Definitive-Guide-master/data/flight-data/json/2011-summary.json\")\n",
    "#dfjson.printSchema()\n",
    "#dfjson.show(10)\n",
    "\n",
    "#schema inference\n",
    "#spark.read.format(\"json\").load(\"file:///Users/jackshalu/Documents/Spark-The-Definitive-Guide-master/data/flight-data/json/2015-summary.json\").schema\n",
    "\n",
    "#Manual Schema\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col,expr\n",
    "\n",
    "mySchema = StructType([StructField(\"DEST_COUNTRY_NAME\",StringType(),False),StructField(\"ORIGIN_COUNTRY_NAME\",StringType(),False),StructField(\"count\",LongType(),True)])\n",
    "dfjson = spark.read.format(\"json\").schema(mySchema).load(\"file:///Users/jackshalu/Documents/Spark-The-Definitive-Guide-master/data/flight-data/json/2015-summary.json\")\n",
    "dfjson.printSchema()\n",
    "dfjson.show()\n",
    "\n",
    "'''\n",
    "col and expr\n",
    "\n",
    "col(count) + 10\n",
    "expr (\"(count) + 10\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Programmatic accessing columns\n",
    "dfjson.columns\n",
    "\n",
    "#create Row and Dataframe\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col,lit,current_timestamp\n",
    "\n",
    "exschema = StructType([StructField(\"Fname\",StringType(),True),StructField(\"Lname\",StringType(),True),StructField(\"Age\",LongType(),True)])\n",
    "\n",
    "myRow = [Row(\"Jaga\",\"Jaya\",32),Row(\"Salini\",\"Venu\",25)]\n",
    "\n",
    "exDF = spark.createDataFrame(myRow,exschema)\n",
    "\n",
    "exDF.show()\n",
    "\n",
    "#Select and Selectexpr\n",
    "\n",
    "dfjson.select(\"DEST_COUNTRY_NAME\",\"ORIGIN_COUNTRY_NAME\").show()\n",
    "dfjson.select(col(\"count\") + 10).show()\n",
    "dfjson.selectExpr(\"count + 10 as expr10\",\"DEST_COUNTRY_NAME\").show()\n",
    "\n",
    "#dfjson.withColumn(\"WithinCountry\", col(\"DEST_COUNTRY_NAME\") == col(\"ORIGIN_COUNTRY_NAME\")).show()\n",
    "dfjson.selectExpr(\"*\",\"DEST_COUNTRY_NAME in (ORIGIN_COUNTRY_NAME) as winthinCountry\").show()\n",
    "dfjson.selectExpr(\"*\",\"DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME as winthinCountry\").show\n",
    "dfjson.selectExpr(\"avg(count)\",\"count(distinct(DEST_COUNTRY_NAME))\").show()\n",
    "\n",
    "#Literals\n",
    "\n",
    "dfjson.select(expr(\"*\"),lit(current_timestamp()).alias(\"Date\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding and Renaming a Column\n",
    "\n",
    "dfjson.withColumn(\"count-10\",expr(\"count - 10\")).show()\n",
    "dfjson.withColumnRenamed(\"DEST_COUNTRY_NAME\",\"destination\").show()\n",
    "dfwithLongname = dfjson.withColumn(\"This is Long Column-name\",expr(\"DEST_COUNTRY_NAME\"))\n",
    "dfwithLongname.selectExpr(\"`This is Long Column-name`\").show()\n",
    "\n",
    "#Removing a Column\n",
    "dfwithLongname.drop(\"This is Long Column-name\").columns\n",
    "\n",
    "#Changing a Column Type\n",
    "dfnew = dfjson.withColumn(\"count-5\",expr(\"count - 5\").cast(LongType()))\n",
    "dfnew.printSchema()\n",
    "\n",
    "#Filter\n",
    "\n",
    "dfnew.filter((col(\"count\") > 300) & (col(\"count-5\") > 9)).show()\n",
    "dfnew.where(col(\"count\") > 300).where(col(\"DEST_COUNTRY_NAME\") == \"United States\").show()\n",
    "\n",
    "spark.read.json(\"/data/flight-data/json/2015-summary.json\")\\  \n",
    ".createOrReplaceTempView(\"some_sql_view\") # DF => SQL\n",
    "spark.sql(\"\"\"SELECT DEST_COUNTRY_NAME, sum(count) FROM some_sql_view GROUP BY DEST_COUNTRY_NAME\"\"\")\\  \n",
    ".where(\"DEST_COUNTRY_NAME like 'S%'\").where(\"`sum(count)` > 10\")\\ \n",
    ".count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample data\n",
    "\n",
    "dfjson.sample(withReplacement = True, fraction = 0.5,seed = 5).count()\n",
    "\n",
    "#Split data\n",
    "\n",
    "splitData = dfjson.randomSplit([0.25,0.75])\n",
    "\n",
    "splitData[0].count()\n",
    "splitData[1].count()\n",
    "\n",
    "#Sorting rows\n",
    "\n",
    "from pyspark.sql.functions import desc, asc\n",
    "\n",
    "dfjson.orderBy(expr(\"count desc\")).show()\n",
    "dfjson.orderBy(col(\"DEST_COUNTRY_NAME\").asc(),col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repartition and Coalesce\n",
    "\n",
    "#repartition - change the partition with shuffle data\n",
    "#coalesce - increase or decrease the partition without shuffle\n",
    "\n",
    "dfjson.repartition(3)\n",
    "dfjson.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
