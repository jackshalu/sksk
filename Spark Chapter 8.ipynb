{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext,SparkConf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession.builder.appName(\"Chapter8\").getOrCreate()\n",
    "    sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = spark.createDataFrame([\n",
    "    (0, \"Bill Chambers\", 0, [100]),\n",
    "    (1, \"Matei Zaharia\", 1, [500, 250, 100]),\n",
    "    (2, \"Michael Armbrust\", 1, [250, 100])])\\\n",
    "  .toDF(\"id\", \"name\", \"graduate_program\", \"spark_status\")\n",
    "\n",
    "graduateProgram = spark.createDataFrame([\n",
    "    (0, \"Masters\", \"School of Information\", \"UC Berkeley\"),\n",
    "    (2, \"Masters\", \"EECS\", \"UC Berkeley\"),\n",
    "    (1, \"Ph.D.\", \"EECS\", \"UC Berkeley\")])\\\n",
    "  .toDF(\"id\", \"degree\", \"department\", \"school\")\n",
    "sparkStatus = spark.createDataFrame([\n",
    "    (500, \"Vice President\"),\n",
    "    (250, \"PMC Member\"),\n",
    "    (100, \"Contributor\")])\\\n",
    "  .toDF(\"id\", \"status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinExpression = person[\"graduate_program\"] == graduateProgram['id']\n",
    "\n",
    "#Inner\n",
    "\n",
    "joinType = \"inner\"\n",
    "person.join(graduateProgram, joinExpression,joinType).show()\n",
    "\n",
    "#outer\n",
    "joinType = \"outer\"\n",
    "person.join(graduateProgram, joinExpression,joinType).show()\n",
    "\n",
    "#Left outer\n",
    "joinType = \"left_outer\"\n",
    "graduateProgram.join(person, joinExpression,joinType).show()\n",
    "\n",
    "#Right Outer\n",
    "joinType = \"right_outer\"\n",
    "person.join(graduateProgram, joinExpression,joinType).show()\n",
    "\n",
    "#Join in Complex Types\n",
    "\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "person.withColumnRenamed(\"id\", \"personId\")\\\n",
    "  .join(sparkStatus, expr(\"array_contains(spark_status, id)\")).show()\n",
    "\n",
    "#three overcome the challenges for join\n",
    "#Use string instead of boolean on=\"sample\"\n",
    "person.join(gradProgramDupe,\"graduate_program\").select(\"graduate_program\").show()\n",
    "#Drop the column after the join\n",
    "person.join(gradProgramDupe, joinExpr).drop(person.col(\"graduate_program\"))\n",
    "  .select(\"graduate_program\").show()\n",
    "#Rename the clolumn before the join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spark join performance\n",
    "\n",
    "#Shuffle Join - very expensive - need to do intelligent partitioning\n",
    "#Broacast join - no expensive - Big table to small table - broadcast small table to all worker node in order to avoid shuffle\n",
    "\n",
    "from 90 pyspark.sql.functions import broadcast\n",
    "#perform broadcast function use only small dataframe\n",
    "person.join(broadcast(graduateProgram), joinExpr).explain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
